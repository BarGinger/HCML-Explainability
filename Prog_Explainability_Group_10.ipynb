{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMSxpJAkqYzk"
   },
   "source": [
    "# Programming Assignment II: Explainability\n",
    "\n",
    "In this assignment you will train machine learning models and experiment with techniques discussed in the lectures.\n",
    "This assignment makes use of existing Python libraries for some questions. We have provided links to tutorials/examples if you're not familiar with them yet.\n",
    "\n",
    "All code that you implement should be in this notebook. You should submit:\n",
    "* This notebook with your code added. Make sure to add enough documentation. Also provide complete answers to the more theoretical questions in this notebook. These questions are followed by an 'answer indent':\n",
    "> Answer:\n",
    "\n",
    "The notebook .ipynb should have the name format `Prog_Explainability_Group_X.ipynb`, where X is your programming group ID.\n",
    "\n",
    "Important notes:\n",
    "* Deadline for this assignment is **Friday, May 30, 17:00**.\n",
    "* Send it to both Maria Muratidi (m.mouratidi@uu.nl) and Heysem Kaya (h.kaya@uu.nl), CCing your programming partner.\n",
    "* Title of the email: [INFOMHCML] Explainability programming assignment submission [X], with X the number of your group.\n",
    "* There will be a lab session to assist you with the assignment on **Tuesday, May 27, between 11:00-12:45 at DALTON 500 - 6.27 and DALTON 500 - 8.27**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name and student numbers\n",
    "Bar Melinarskiy - 2482975\n",
    "\n",
    "Julia Baas - 6082826\n",
    "\n",
    "**Group number**: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moyaViIx8WzS"
   },
   "source": [
    "### Installation\n",
    "\n",
    "For this assignment, we are going to use the following Python packages:\n",
    "graphviz, matplotlib, pandas, statsmodels, openpyxl, interpret, and scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EaC6P7RqXOh"
   },
   "outputs": [],
   "source": [
    "# Installing packages\n",
    "!pip install graphviz\n",
    "!pip install matplotlib pandas statsmodels openpyxl\n",
    "!pip install interpret\n",
    "!pip install scikit-learn --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeSC0_WEpY0k"
   },
   "source": [
    "### Read the data\n",
    "We are going to use the ChaLearn LAP-FI (First Impressions) Dataset. This dataset contains 10.000 data points, which correspond to videos collected from YouTube and annotated via Amazon Mechanical Turk for the BIG-5 personality impressions: openness, extraversion, conscientiousness, neuroticism, agreeableness.\n",
    "\n",
    "These five personality impression scores will be used as features to predict the outcome variable: a job interview invitation.\n",
    "\n",
    "For a detailed description, see the [paper of the dataset](https://ieeexplore.ieee.org/abstract/document/7966041?casa_token=1Y03H5ykCqsAAAAA:VLhCcjAgByJ2hTdKhulmIUiXIVepEJfFyB7HM0XVts7bN8Gi8wMsiTT0qZ--I_kq8wiUHIpPN7es).\n",
    "\n",
    "\n",
    "1.   If you use Google Colab, upload 'all_df.csv' (you can find this file on blackboard) through the upload button in the Files tab.\n",
    "  - Copy the path of the file;\n",
    "  - Run the cell below with your path. This will ask you for permission to access your Google Drive files and then you can access the data.\n",
    "2.   If you are running this notebook at your own machine (jupyter notebook), locate the 'all_df.csv' file in the same folder this notebook exists. Then you can run the second cell below.\n",
    "\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "okPuwNvww9F-"
   },
   "outputs": [],
   "source": [
    "def is_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "    \n",
    "if is_colab():\n",
    "    # Run this cell only if you use Google Colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "\n",
    "    # Make sure you uploaded all_df.csv to your Google Drive and change the path\n",
    "    # to the directory it is located in (usually in content/gdrive/MyDrive/...)\n",
    "    %cd  '/content/gdrive/MyDrive/HCML/Explainability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fleSmPrE7UMT"
   },
   "outputs": [],
   "source": [
    "# Run this cell (both when working locally or with Google Colab)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"all_df.csv\")\n",
    "print(\"Data loaded\")\n",
    "np.random.seed(42)  # For reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQpW5C3Sg9YA"
   },
   "source": [
    "### Loading and preprocessing the data\n",
    "There are 6000, 2000 and 2000 examples for training, validation/development and test set respectively. In the data this is indicated by the feature `split`.\n",
    "\n",
    "The training set is used to train models, the validation/development set to optimize the models hyper-parameters, and the test set to evaluate the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JycjPmn_7p41"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# global variables\n",
    "FEATURE_NAMES = ['extraversion', 'neuroticism', 'agreeableness', 'conscientiousness', 'openness']\n",
    "LABEL_NAME = 'interview'\n",
    "\n",
    "def load_data():\n",
    "    def split_feature_label(data_set):\n",
    "        features = data_set[FEATURE_NAMES]\n",
    "        labels = data_set[LABEL_NAME]\n",
    "        return features, labels\n",
    "\n",
    "    train_set = data[data['split'] == 'training']\n",
    "    val_set = data[data['split'] == 'validation']\n",
    "    test_set = data[data['split'] == 'test']\n",
    "\n",
    "    train_features, train_labels = split_feature_label(train_set)\n",
    "    val_features, val_labels = split_feature_label(val_set)\n",
    "    test_features, test_labels = split_feature_label(test_set)\n",
    "\n",
    "    return train_features, train_labels, val_features, \\\n",
    "        val_labels, test_features, test_labels\n",
    "\n",
    "# Load the data with the function above\n",
    "(train_features, train_labels, dev_features, \\\n",
    "        dev_labels, test_features, test_labels) = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Show the DataFrame in a scrollable box (adjust height as needed)\n",
    "print(\"Train features:\")\n",
    "display(HTML(train_features.to_html(max_rows=10, \n",
    "                                    max_cols=100, \n",
    "                                    notebook=True,\n",
    "                                    show_dimensions=True,\n",
    "                                    justify='center', \n",
    "                                    border=1, \n",
    "                                    table_id=\"scroll_df\")))\n",
    "print(\"Train labels:\")\n",
    "display(HTML(train_labels.to_frame().to_html(max_rows=10, \n",
    "                                              max_cols=100, \n",
    "                                              notebook=True,\n",
    "                                              show_dimensions=True,\n",
    "                                              justify='center', \n",
    "                                              border=1, \n",
    "                                              table_id=\"scroll_df\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbkcGeJT6stA"
   },
   "source": [
    "# Part 1. Different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QabF2JOdMTI4"
   },
   "source": [
    "### **1. Linear Regression**\n",
    "\n",
    "Train a linear regression model (we recommend the `statsmodels.api` package with the ordinary least squares model `sm`).\n",
    "\n",
    "Hint: to get a linear regression model, you should manually add a constant variable (usually called bias or intercept - that has a fixed value of 1 for all instances) to the data, either by adding it column yourself or by using the `add_constant()` function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fg6Tc7uD6jL_"
   },
   "source": [
    "**Q1.1**\n",
    "\n",
    "Provide the $R^2$ (goodness of fit) statistic and for each feature (+ the bias variable), the following in tabular format:\n",
    "* Weight estimate (coef)\n",
    "* SE (standard error of estimates)\n",
    "* T-statistic\n",
    "\n",
    "Hint: You can print the summary of the model using `.summary()` to do this. This gives an extensive overview of the performance of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B91BszFhMStw"
   },
   "outputs": [],
   "source": [
    "# We recommend the statsmodels package\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Your code to add a bias/intercept variable\n",
    "train_features_with_const = sm.add_constant(train_features)\n",
    "\n",
    "# Fit and summarize OLS model\n",
    "linear_reg_model = sm.OLS(train_labels, train_features_with_const)\n",
    "linear_reg_model_res = linear_reg_model.fit() # fit the linear regression model\n",
    "print(linear_reg_model_res.summary())\n",
    "\n",
    "print(\"\\n*********************************************************************************************\")\n",
    "linear_reg_test_predictions = linear_reg_model_res.predict(sm.add_constant(test_features))\n",
    "linear_reg_mse = mean_squared_error(test_labels, linear_reg_test_predictions)\n",
    "print(\"Linear Regression MSE on test: {:.4f}\".format(linear_reg_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the top three most important coefficients by absolute value (excluding the intercept)\n",
    "linear_reg_coefficients = linear_reg_model_res.params.drop('const').abs().sort_values(ascending=False)\n",
    "top3 = linear_reg_coefficients.head(3)\n",
    "for i, (feature, coef) in enumerate(top3.items(), 1):\n",
    "    print(f\"{i}. Feature: {feature}, |Coefficient|: {coef:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQSPWuVzNBmX"
   },
   "source": [
    "**Q1.2**\n",
    "\n",
    "Which three features are the most important?\n",
    "\n",
    "> Answer:\n",
    "\n",
    "**The top three most important features (excluding the bias) are:**  \n",
    "1. conscientiousness (0.329)  \n",
    "2. agreeableness (0.257)  \n",
    "3. neuroticism (0.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conscientiousness_coef = linear_reg_model_res.params['conscientiousness']\n",
    "delta = 0.1  # increase in feature\n",
    "change_in_prediction = conscientiousness_coef * delta\n",
    "print(f\"If 'conscientiousness' increases by 0.1, the predicted interview score changes by {change_in_prediction:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6miEyz_f66Ei"
   },
   "source": [
    "**Q1.3**\n",
    "\n",
    "How does the predicted 'interview' score change with an 0.1 increase of the 'conscientiousness' feature given that all other feature values remain the same?\n",
    "\n",
    "> Answer:\n",
    "**If 'conscientiousness' increases by 0.1, the predicted interview score changes by 0.0329**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AlVsA0ZhWbw"
   },
   "source": [
    "**Q1.4**\n",
    "\n",
    "Show bar graph illustrations of the feature effects for the first two validation set instances.\n",
    "\n",
    "> Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "abB-9YswhkMo"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get coefficients (excluding intercept)\n",
    "coefs = linear_reg_model_res.params.drop('const')\n",
    "\n",
    "# Get the first two validation instances\n",
    "first_two = dev_features.iloc[:2]\n",
    "\n",
    "features = coefs.index\n",
    "x = np.arange(len(features))\n",
    "width = 0.35  # width of the bars\n",
    "\n",
    "colors = plt.get_cmap('Set2').colors\n",
    "\n",
    "# Compute effects for both instances\n",
    "effects_0 = first_two.iloc[0] * coefs\n",
    "effects_1 = first_two.iloc[1] * coefs\n",
    "\n",
    "# Print feature effects for both instances\n",
    "print(\"Instance 0 linear model feature effects:\")\n",
    "for feat, eff in zip(features, effects_0):\n",
    "    print(f\"{feat}: {eff:.4f}\")\n",
    "\n",
    "print(\"\\nInstance 1 linear model feature effects:\")\n",
    "for feat, eff in zip(features, effects_1):\n",
    "    print(f\"{feat}: {eff:.4f}\")\n",
    "\n",
    "# Create a bar plot for the first two validation instances (single plot with two sets of bars)\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "bars1 = ax.bar(x - width/2, effects_0.values, width, label='Instance 0', color=colors[0])\n",
    "bars2 = ax.bar(x + width/2, effects_1.values, width, label='Instance 1', color=colors[1])\n",
    "\n",
    "ax.set_ylabel('Effect on Prediction', fontsize=12, color='lightblue', weight='bold')\n",
    "ax.set_xlabel('Feature', fontsize=12, color='lightblue', weight='bold')\n",
    "ax.set_title('Feature Effects for First Two Validation Instances', fontsize=15, color='lightblue', weight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(features)\n",
    "ax.grid(axis='y')\n",
    "ax.legend()\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontsize=9, weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine features and label into one DataFrame for correlation\n",
    "corr_df = train_features.copy()\n",
    "corr_df['interview'] = train_labels\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = corr_df.corr()\n",
    "\n",
    "# Plot correlation matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix between Features and Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tj6Pri4HBeO"
   },
   "source": [
    "**Q1.5**\n",
    "\n",
    "Reflection: why would training a regression tree not work well for this dataset in terms of model interpretability? And under what conditions could the dataset be used with a decision tree to yield an interpretable model?\n",
    "\n",
    "> Answer:\n",
    "\n",
    "**Training a regression tree is not ideal for this dataset in terms of model interpretability. Since the output is continuous rather than binary (as in a classification tree), the resulting model tends to be more complex and deeper, making it harder to interpret. The correlation matrix displayed above shows that all five personality traits are strongly correlated with the interview outcome (correlations ≥ 0.77), and also with each other (e.g., extraversion and neuroticism: 0.80). These strong correlations increase the chance of the tree making many small, overlapping splits to reduce error, which can lead to overfitting and overly long decision paths that are difficult to understand.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7r09mMfeo2k"
   },
   "source": [
    "### **2. Explainable Boosting Model**\n",
    "Train an Explainable Boosting Machine (EBM) with [InterpretML](https://interpret.ml/docs/ebm.html). EBM is a Generalized Additive Model (GAM) that is highly intelligible and explainable.\n",
    "\n",
    "The `interpret` package provides both global and local explanation functions: `explain_global()` and `explain_local()` can be used to interpret a ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUxfqAHb7ZgX"
   },
   "source": [
    "**Q2.1**\n",
    "\n",
    "Visualize/provide global (model-wise) feature importances for EBM as a table or figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbqYT0Wh34k-"
   },
   "outputs": [],
   "source": [
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "from interpret import show\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# Train EBM\n",
    "ebm = ExplainableBoostingRegressor()\n",
    "ebm.fit(train_features, train_labels)\n",
    "show(ebm.explain_global())\n",
    "\n",
    "print(\"\\n*********************************************************************************************\")\n",
    "ebm_test_predictions = ebm.predict(test_features)\n",
    "ebm_mse = mean_squared_error(test_labels, ebm_test_predictions)\n",
    "print(\"Explainable Boosting Machine MSE on test: {:.4f}\".format(ebm_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "global_exp = ebm.explain_global()\n",
    "features = list(train_features.columns)\n",
    "importances = []\n",
    "\n",
    "for i in range(len(features)):\n",
    "    # For importance, sum the absolute values of the scores\n",
    "    scores = global_exp.data(i)['scores']\n",
    "    importance = sum(abs(s) for s in scores)\n",
    "    importances.append(importance)\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': importances}).sort_values('Importance', ascending=False)\n",
    "print(\"\\nEBM Global Feature Importances Table:\")\n",
    "display(HTML(importance_df.to_html(max_rows=10, \n",
    "                                              max_cols=100, \n",
    "                                              notebook=True,\n",
    "                                              index=False,\n",
    "                                              show_dimensions=True,\n",
    "                                              justify='center', \n",
    "                                              border=1, \n",
    "                                              table_id=\"importance_df\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cJ1uiHf34_l"
   },
   "source": [
    "**Q2.2**\n",
    "\n",
    "What are the most important two features in EBM? Are they the same as in the linear model?\n",
    "\n",
    "> Answer:\n",
    "**The top three most important features for EBM are:**  \n",
    "1. conscientiousness (7.181)  \n",
    "2. neuroticism (4.684)\n",
    "3. agreeableness (4.300) \n",
    "\n",
    "Which are the same three features from the top three features for Linear Regression (just in a slightly different order):\n",
    "1. conscientiousness (0.329)  \n",
    "2. agreeableness (0.257)  \n",
    "3. neuroticism (0.24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUxRg7Xr7hr1"
   },
   "source": [
    "Now, to have an idea how EBM treats the input and generates the explanation, visualize EBM local explanations on a synthetic instance generated from training set mean feature vector as input and training set mean response as output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BieO0LiSceUd"
   },
   "outputs": [],
   "source": [
    "from interpret import show\n",
    " \n",
    "# EBM Local explanation for training set mean vector with corresponding training set mean label\n",
    "train_mean_x = pd.DataFrame(train_features.mean(axis=0)).T\n",
    "train_mean_y = pd.DataFrame([train_labels.mean()])\n",
    "\n",
    "print(train_mean_x)\n",
    "print(train_mean_y)\n",
    "\n",
    "ebm_local_exp = ebm.explain_local(train_mean_x, train_mean_y)\n",
    "show(ebm_local_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TMeydtDsB35"
   },
   "source": [
    "**Q2.3**\n",
    "\n",
    "Now, visualize local (instance-wise) feature importances for the first two instances of the development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ce00C36ilxxC"
   },
   "outputs": [],
   "source": [
    "# EBM local explanations for the first two development set instances\n",
    "from interpret import show\n",
    "\n",
    "# Select the first two instances from the development set\n",
    "first_two_dev = dev_features.iloc[:2]\n",
    "first_two_labels = dev_labels.iloc[:2]\n",
    "\n",
    "# Get local explanations for these two instances\n",
    "ebm_local_exp = ebm.explain_local(first_two_dev, first_two_labels)\n",
    "\n",
    "# Visualize in the notebook (interactive)\n",
    "show(ebm_local_exp)\n",
    "\n",
    "# If you want to print the feature contributions as a table for each instance:\n",
    "for i in range(2):\n",
    "    print(f\"\\nInstance {i+1} local explanation:\")\n",
    "    names = ebm_local_exp.data(i)['names']\n",
    "    scores = ebm_local_exp.data(i)['scores']\n",
    "    for name, score in zip(names, scores):\n",
    "        print(f\"{name}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EBM Local explanation for the first two validation instances\n",
    "# plot to answer question 2.4\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# --- Get linear model effects ---\n",
    "coefs = linear_reg_model_res.params.drop('const')\n",
    "first_two = dev_features.iloc[:2]\n",
    "features = list(coefs.index)\n",
    "\n",
    "effects_linear_0 = first_two.iloc[0] * coefs\n",
    "effects_linear_1 = first_two.iloc[1] * coefs\n",
    "\n",
    "# --- Get EBM effects ---\n",
    "ebm_names_0 = ebm_local_exp.data(0)['names']\n",
    "ebm_scores_0 = ebm_local_exp.data(0)['scores']\n",
    "ebm_names_1 = ebm_local_exp.data(1)['names']\n",
    "ebm_scores_1 = ebm_local_exp.data(1)['scores']\n",
    "\n",
    "def filter_main_effects(names, scores):\n",
    "    filtered = [(n, s) for n, s in zip(names, scores) if '&' not in n]\n",
    "    return dict(filtered)\n",
    "\n",
    "ebm_main_0 = filter_main_effects(ebm_names_0, ebm_scores_0)\n",
    "ebm_main_1 = filter_main_effects(ebm_names_1, ebm_scores_1)\n",
    "\n",
    "x = np.arange(len(features))\n",
    "width = 0.2\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "for idx, (effects_linear, ebm_main, instance_label) in enumerate([\n",
    "    (effects_linear_0, ebm_main_0, \"Instance 1\"),\n",
    "    (effects_linear_1, ebm_main_1, \"Instance 2\")\n",
    "]):\n",
    "    # Get values for ranking\n",
    "    linear_vals = np.array([effects_linear[f] for f in features])\n",
    "    ebm_vals = np.array([ebm_main.get(f, 0) for f in features])\n",
    "    # Rankings (1 = highest contribution)\n",
    "    linear_ranks = linear_vals.argsort()[::-1].argsort() + 1\n",
    "    ebm_ranks = ebm_vals.argsort()[::-1].argsort() + 1\n",
    "\n",
    "    bars1 = axs[idx].bar(x - width/2, linear_vals, width, label='Linear', color='skyblue')\n",
    "    bars2 = axs[idx].bar(x + width/2, ebm_vals, width, label='EBM', color='orange')\n",
    "    axs[idx].set_xticks(x)\n",
    "    axs[idx].set_xticklabels(features, rotation=45, fontsize=16)\n",
    "    axs[idx].set_title(instance_label, color='lightblue', weight='bold', fontsize=18)\n",
    "    axs[idx].set_ylabel('Feature Contribution', weight='bold', fontsize=12)\n",
    "    axs[idx].legend()\n",
    "    axs[idx].grid(axis='y')\n",
    "    # Add value and rank labels for linear regression bars\n",
    "    for i, bar in enumerate(bars1):\n",
    "        height = bar.get_height()\n",
    "        axs[idx].annotate(f'{height:.3f}',\n",
    "                          xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                          xytext=(0, 3),\n",
    "                          textcoords=\"offset points\", color='yellow',\n",
    "                          ha='center', va='bottom', fontsize=13, weight='bold')\n",
    "        axs[idx].annotate(f'#{linear_ranks[i]}',\n",
    "                          xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                          xytext=(0, 20),\n",
    "                          textcoords=\"offset points\", color='red',\n",
    "                          ha='center', va='bottom', fontsize=12, weight='bold')\n",
    "        \n",
    "    # Add value and rank labels for EBM bars\n",
    "    for i, bar in enumerate(bars2):\n",
    "        height = bar.get_height()\n",
    "        axs[idx].annotate(f'{height:.3f}',\n",
    "                          xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                          xytext=(0, 3),\n",
    "                          textcoords=\"offset points\", color='yellow',\n",
    "                          ha='center', va='bottom', fontsize=13, weight='bold')\n",
    "        axs[idx].annotate(f'#{ebm_ranks[i]}',\n",
    "                          xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                          xytext=(0, 20),\n",
    "                          textcoords=\"offset points\", color='green',\n",
    "                          ha='center', va='bottom', fontsize=12, weight='bold')\n",
    "\n",
    "plt.suptitle('Feature Contributions: Linear Model vs EBM', fontsize=20, color='lightpink', weight='bold')\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTFmCfAn5xQK"
   },
   "source": [
    "**Q2.4**\n",
    "\n",
    "Let's compare these feature importances with the feature effects in question 1.4.\n",
    "\n",
    "* Are the feature contribution orderings the same in both models for the two instances?\n",
    "> Answer:\n",
    "**No, the feature contribution orderings are not exactly the same between the two models for both instances. As shown in the figure, we included the ranking for each feature above the bars (red for linear regression, green for EBM). In the first instance, both models agree on the most and least important features (conscientiousness and openness, respectively), but they differ on the others—for example, EBM ranks extraversion second, while linear regression ranks agreeableness second. In the second instance, the models only agree on the top two features (conscientiousness and neuroticism). However, agreeableness is ranked third by linear regression but drops to fifth (and even has a negative contribution) in the EBM model. This highlights that while there is some overlap, the models do not produce identical feature importance rankings for individual cases.**\n",
    "\n",
    "* For the second example's explanation, why do you think the contribution of *conscientiousness* is positive, while the contribution of *agreeableness* is negative? (Hint: consider the feature values relative to the training set mean values you calculated / processed in the former subquestion.)\n",
    "> Answer:\n",
    "\n",
    "**This difference arises from how EBM models each feature's effect individually, using data-driven, non-linear shape functions that capture how prediction changes as a feature value varies.**\n",
    "\n",
    "**The positive contribution of conscientiousness suggests that the individual's score on this trait is in a region where the EBM model associates higher values with an increase in the predicted outcome.**\n",
    "\n",
    "**In contrast, the negative contribution from agreeableness implies that the individual's value for agreeableness lies in a region of the EBM shape function where higher values contribute negatively to the prediction, or their value is lower than average and the model penalizes that.**\n",
    "\n",
    "**Since EBM learns these effects directly from the training data, the direction and size of the contribution depend on:**\n",
    "- **The location of the feature value relative to key turning points in the learned shape,**\n",
    "- **Whether that value falls in an increasing or decreasing region, and**\n",
    "- **The magnitude of the learned effect at that point.**\n",
    "\n",
    "**So, although agreeableness is ranked highly by the linear model - in 3rd place, EBM captures a non-linear, potentially diminishing or reversing effect for this instance—leading to its negative influence in this case.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_k7dAwTIfbsc"
   },
   "source": [
    "# Part 2. Model-Agnostic Methods for Interpreting/Explaining NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EbowFSZAZj6"
   },
   "source": [
    "### **3. Training Neural Networks**\n",
    "Train a one-layer Neural Network (multi-layer perceptron (MLP) Regressor, but with one layer) with the following settings:\n",
    "\n",
    "- Activation function: ReLU\n",
    "- Size of the hidden layer: 50 neurons\n",
    "- Recommended optimizer/solver: Adam\n",
    "\n",
    "For a tutorial see [Tutorial](https://scikit-learn.org/stable/modules/neural_networks_supervised.html).\n",
    "\n",
    "**Q3.1**\n",
    "\n",
    "Apply the trained neural network model to the development set to find the best hyperparameters (such as learning rate). Report the Root Mean Square Error (RMSE) performance measure.\n",
    "\n",
    "**Note.** A development set RMSE below 0.045 is reasonable, then you can apply the corresponding model on the test set in the next question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQjg_qtCf_WD"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#changing the names so we don't get confused \n",
    "X_train = train_features\n",
    "y_train = train_labels\n",
    "X_val   = dev_features\n",
    "y_val   = dev_labels\n",
    "X_test  = test_features\n",
    "y_test  = test_labels\n",
    "\n",
    "clf = MLPRegressor(hidden_layer_sizes=(50), activation='relu', solver='adam', alpha=0.0001, batch_size=128, learning_rate_init=0.001)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#predict the validation set\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "#evaluating:\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(f\"RMSE is {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQySPj5Nt_sO"
   },
   "source": [
    "**Q3.2**\n",
    "\n",
    "Now use the best settings to report the Root Mean Square Error (RMSE) performance measure on the test set.\n",
    "\n",
    "It is possible to use the combination of the training and development sets to retrain the model and report the test set performance. You can also use the model that was trained on the training set only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxuJUUUnPgGb"
   },
   "outputs": [],
   "source": [
    "#predict the validation set\n",
    "y_pred2 = clf.predict(X_test)\n",
    "\n",
    "#evaluating:\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred2))\n",
    "print(f\"RMSE is {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huX2fiH1-Qir"
   },
   "source": [
    "Now we can analyze factors that influence the predictions. Both Partial Dependence Plots (PDP) and Individual Conditional Expectation (ICE) plots can be used to visualize and analyze interaction between the target response and a set of input features of interest.\n",
    "\n",
    "See the [Documentation](https://scikit-learn.org/stable/modules/partial_dependence.html) on how to use PDPs and ICEs.\n",
    "\n",
    "**Q3.3**\n",
    "\n",
    "Generate univariate and bivariate PDPs for the `conscientiousness` and `agreeableness` features with the neural network you trained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqVV2yHdpSdl"
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Generating the univariate PDP's:\n",
    "PartialDependenceDisplay.from_estimator(clf, X_test, ['conscientiousness'], line_kw={'color': 'red'})\n",
    "PartialDependenceDisplay.from_estimator(clf, X_test, ['agreeableness'])\n",
    "\n",
    "#Generating the bivariate PDP:\n",
    "PartialDependenceDisplay.from_estimator(clf, X_test, [('conscientiousness', 'agreeableness')])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M584ROYo1czo"
   },
   "source": [
    "**Q3.4**\n",
    "\n",
    "What do these plots show?\n",
    "\n",
    "> Answer: The first two plots show the impact of conscientiousness and agreeableness on the outcome respectively. They have a similar trend: for both features hold that the higher the feature, the more likely someone is to be interviewed. The agreeableness has more influence when it has a lower value than 0.5 when it has a higher value.\n",
    "The second plot shows the impact of both conscientiousness and agreeableness (as an interactive pair) on the outcome. As you can see, the factors influence each other: only if a person has both a high conscientiousness score and a high agreeableness score, they are likely to be interviewed. If one of the scores is low, it lowers the total outcome. Just having one high score is not enough. So the plot shows the features interact.\n",
    "\n",
    "\n",
    "**Q3.5**\n",
    "\n",
    "Now generate ICE plots for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ig_iwDVqQBdY"
   },
   "outputs": [],
   "source": [
    "# ICEs\n",
    "import matplotlib.pyplot as plt\n",
    "PartialDependenceDisplay.from_estimator(clf, X_test, ['conscientiousness'], kind = 'individual', line_kw={'color': 'red'})\n",
    "PartialDependenceDisplay.from_estimator(clf, X_test, ['agreeableness'], kind = 'individual', line_kw={'color': 'blue'})\n",
    "PartialDependenceDisplay.from_estimator(clf, X_test, ['neuroticism'], kind = 'individual', line_kw={'color': 'green'})\n",
    "PartialDependenceDisplay.from_estimator(clf, X_test, ['openness'], kind = 'individual', line_kw={'color': 'yellow'})\n",
    "PartialDependenceDisplay.from_estimator(clf, X_test, ['extraversion'], kind = 'individual', line_kw={'color': 'orange'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y75fIVlY2abm"
   },
   "source": [
    "**Q3.6**\n",
    "\n",
    "What can you conclude from ICE plots above?\n",
    "\n",
    "> Answer:  It shows that all the samples react similarly to a change in these features, there are no lines that follow a different direction than the other lines in a plot. Furthermore, for most features it holds that the higher the value, the higher the likelihood that someone is interviewed. However, for openess the lines are almost flat, which means that if the openess increases by a lot, the likelihood does not increase that much. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0NLZmwHv5tx"
   },
   "source": [
    "**Q3.7**\n",
    "\n",
    "Implement the PDF (Partial Dependence Function) for univariate analysis of the trained NN model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nyRSmdVD9LF8"
   },
   "outputs": [],
   "source": [
    "def PDF(X, model, feature):\n",
    "    \n",
    "  num_samples = X.shape[0]    # set the number of samples/steps to slice the range of the continuous feature, e.g., 100.\n",
    "  min_val = X[feature].min()     # minimum value of the given feature\n",
    "  max_val = X[feature].max()      # maximum value of the given feature\n",
    "  step_size = (max_val - min_val) / (num_samples)    # see the algorithm in corresponsing lecture slides to calculate the step size as a function of the above variables\n",
    "  x_values = np.arange(min_val, max_val, step_size)     # x_values at which we will calculate the partial function of the given feature\n",
    "  f_values = np.zeros(num_samples)   # the calculated partial function values corresponding to x_values\n",
    "\n",
    "  for k in range(num_samples -1):\n",
    "        X_temp = X.copy()\n",
    "        X_temp[feature] = x_values[k] # Set all rows of that feature to this value\n",
    "        preds = model.predict(X_temp)\n",
    "        f_values[k] = np.mean(preds)  # Average prediction over all rows\n",
    "  return x_values, f_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-erhkuKc9Lbb"
   },
   "source": [
    "**Q3.8**\n",
    "\n",
    "Calculate and visualize the feature importances obtained by your PDF algorithm with a bar graph. How do we calculate the feature importance given the x_values and y_values of the PDF algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwjNZFql9QtZ"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Feature names\n",
    "features = [\"extraversion\", \"neuroticism\", \"agreeableness\", \"conscientiousness\", \"openness\"]\n",
    "\n",
    "# Store importances\n",
    "importances = {}\n",
    "\n",
    "# Looping over features and compute slopes\n",
    "for feature in features:\n",
    "    x_vals, f_vals = PDF(X_val, clf, feature)\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(x_vals, f_vals) #calculate the slope to give the feature importance\n",
    "    importances[feature] = abs(slope)  \n",
    "\n",
    "# Plotting the bar graph\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(importances.keys(), importances.values())\n",
    "plt.ylabel(\"Feature Importance (|slope| of PDF)\")\n",
    "plt.title(\"Feature Importances via Partial Dependence\")\n",
    "plt.grid(True, axis='y')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4I5Z1dRl86BP"
   },
   "source": [
    "**Q3.9**\n",
    "\n",
    "What are the two most important features obtained by the PDF algorithm for the MLP model? How do these two features compare to the top two features from the Linear Model and the EBM?\n",
    "\n",
    "> Answer: The results are very similar, like the Linear Regression model, the PDF gives conscientiousness and agreeableness as the top two features. EBM gave conscientiousness and neuroticism, but agreeableness came at a close third, so the result are quite consistent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8slEz838w8_"
   },
   "source": [
    "### **4. Permutation Feature Importance**\n",
    "\n",
    "**Q4.1**\n",
    "\n",
    "Implement the permutation feature importance algorithm using RMSE as the error function. No existing libraries (barring the RMSE from `sklearn` and a function for random sampling / permutation) are allowed to be used, you will implement it yourself with the framework below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7xUqEYnv4wA"
   },
   "outputs": [],
   "source": [
    "def PFI(X, labels, model, base_rmse):\n",
    "  results = []\n",
    "\n",
    "  for feature in X:\n",
    "    X_temp = X.copy() #Create a copy of X_test\n",
    "    X_temp[feature] = np.random.permutation(X_temp[feature].values) # Permute the feature column\n",
    "    y_pred = model.predict(X_temp)    # Predict with the shuffled data    \n",
    "    rmse = np.sqrt(mean_squared_error(labels, y_pred)) # Calculate the new RMSE\n",
    "    rmse_dif = abs(base_rmse - rmse)\n",
    "    results.append((feature, rmse_dif))\n",
    "    \n",
    "  results_df = pd.DataFrame(results, columns=[\"Feature\", \"Importance\"])\n",
    "  results_df = results_df.sort_values(by=\"Importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "  return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHemT4b73rwY"
   },
   "source": [
    "**Q4.2**\n",
    "\n",
    "Visualize the feature importances obtained by your PFI algorithm with a bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gxZ9pPBoVsdi"
   },
   "outputs": [],
   "source": [
    "base_pred = clf.predict(X_val)\n",
    "base_rmse = np.sqrt(mean_squared_error(y_val, base_pred))\n",
    "\n",
    "# Run permutation feature importance\n",
    "results_df = PFI(X_val, y_val, clf, base_rmse)\n",
    "\n",
    "# Plotting the bar graph\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(results_df['Feature'], results_df['Importance'])\n",
    "plt.ylabel(\"Feature Importance (|slope| of PDF)\")\n",
    "plt.title(\"Feature Importances via Partial Dependence\")\n",
    "plt.grid(True, axis='y')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmvAN-wT336H"
   },
   "source": [
    "**Q4.3**\n",
    "\n",
    "What are the two most important features obtained by the permutation feature importance algorithm for the MLP model? How do these two features compare to the top two features from the Linear Model and the EBM?\n",
    "\n",
    "> Answer: The PFI algorithm gives conscientiousness and neuroticism as the top two, just like the EBM algorithm. However, the importance of agreeableness has decreased compared to the other models. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ExplainableAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
